{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"./files/style.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./files/style.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCL BIOC0016 - Bioinformatics\n",
    "Alan R. Lowe (a.lowe@ucl.ac.uk)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Bioimage informatics / Machine learning\n",
    "\n",
    "The aim of the exercises in this notebook is to familiarise you with the different steps of evaluating the performance of a simple convolutional neural network (CNN). You will use a real CNN to classify different cell states using image data provided to you. A more sophisticated version of this neural network has been used in recently published research. The architecture of the network is similar to those you will have learnt about in the lectures.\n",
    "\n",
    "The network is able to tell whether a cell is proliferating or dead.  This could be useful to understand whether a drug is effective or not, or to understand the normal cellular behaviour.\n",
    "\n",
    "The CNN has been pre-trained on a dataset of real images from data collected at UCL. This is a very simple CNN, and you are going to assess the performance of it by making predictions of the cell state using image data, and comparing these with your ground truth annotation.  The images that you are provided with are called a 'hold out' set, since they have come from the much larger original data set, but have not been used to train the neural network. The CNN has not 'seen' these data during the training phase, and therefore represent a real test of the performance of the network.  \n",
    "\n",
    "The practical contains following sections:\n",
    "\n",
    "1. Data annotation\n",
    "2. Make predictions with a convolutional neural network\n",
    "3. Compare these with the data that you have annotated\n",
    "4. Determine the accuracy of the model\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Code sections are coloured according to the following scheme:\n",
    "\n",
    "* <div class=\"task_red\"> Code that needs to be written by you. </div>\n",
    "* <div class=\"task_blue\"> Code that needs to be edited by you, perhaps changing some parameters. </div>\n",
    "* <div class=\"task_green\"> A task that needs to be completed by you. This may be recording the results. </div>\n",
    "\n",
    "\n",
    "### Be part of the research project!\n",
    "\n",
    "This is based on a real research project, and you can contribute to the project by recording your results as part of the practical. You can read more about the research project [here](http://lowe.cs.ucl.ac.uk/cellx.html).\n",
    "\n",
    "As you complete different sections of the practical, we ask you to complete different sections of a google form. By recording the results, you can contribute to the research programme.\n",
    "\n",
    "### Further reading\n",
    "* http://lowe.cs.ucl.ac.uk/cellx.html\n",
    "* https://en.wikipedia.org/wiki/Bioimage_informatics\n",
    "* https://teachablemachine.withgoogle.com/train/image\n",
    "* https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PRACTICAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 1 - Data Annotation\n",
    "\n",
    "\n",
    "To test how well the neural network is able to perform on unseen images, we need to manually annotate some new and unseen images with a label. We can then count how many labels the neural network correctly predicts. In this section, you will be provided with a random sample of unlabeled images. You will need at least 30, although the more the better. Using the guide below, please annotate each image with one of the six labels provided. If you are unsure, use the 'Unknown' label.\n",
    "\n",
    "Here are some examples of cells and their corresponding labels:\n",
    "\n",
    "![Cell state labels](./files/cell_states.png \"Cell state labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up plotting and import some useful libraries\n",
    "\n",
    "We first need to load some libraries of code that will help with the data processing and visualization. If you are more experienced at Python, you can read the code for the `helpers` library at [github](https://github.com/quantumjot/BIOC0016-MachineLearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import helpers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a sample of images from the test dataset\n",
    "\n",
    "Next, we need to get a random sample of images from the dataset. The dataset has thousands of images in it. The first command `images = helpers.get_example_images()` uses the `helpers` library to call a function `get_example_images`. This requests images from the dataset and places them in a list called `images`.\n",
    "\n",
    "The second command `helpers.plot_images()` takes the list of images as an argument and plots them in a matrix, showing the unique ID numbers above them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = helpers.get_example_images(num_images=10)\n",
    "helpers.plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_blue\"> <b>TASK</b>: Try changing the number of images. For the remainder of the practical, you will need at least 30 images.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your own sample of images, you need to annotate them to create the **ground truth**. You will store these annotations using two Python data structures, a `list` and a `dictionary`.\n",
    "\n",
    "A `list` is just what it sounds like, a sequence of items in order. A list can have multiple entries (separated by commas), or be empty:\n",
    "```python\n",
    "list_of_numbers = [0, 1, 2, 3, 4]\n",
    "empty_list = []\n",
    "```\n",
    "\n",
    "A `dictionary` stores key-value pairs.\n",
    "\n",
    "The final data structure may look something like this:\n",
    "\n",
    "```python \n",
    "annotation = {'interphase': [0,5,3,20], \n",
    "              'prometaphase': [7,2], \n",
    "              'metaphase': [14,33,6], \n",
    "              'anaphase': [508,1], \n",
    "              'apoptosis': [8], \n",
    "              'unknown': []}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_red\">\n",
    "    <b>TASK:</b> Complete the annotation dictionary. To do this you will need to make a list of the image numbers, and your best guess as to the label that each image should have. Once you have this, compile the information into a dictionary structure, and run the validation to make sure that the annotation format is correct. If the validation returns True, you can copy the annotation cell to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdhPIHCMvtHVUCe-7_XYHujWIW2mq7SzcA2mfYh6LHiZ2LUPQ/viewform\">Google form</a>.          \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = {'prometaphase': [893]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the annotation\n",
    "helpers.validate_annotation(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_green\">\n",
    "    <b>TASK:</b> Complete the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdhPIHCMvtHVUCe-7_XYHujWIW2mq7SzcA2mfYh6LHiZ2LUPQ/viewform\">Google form</a>, to record the annotations you have made\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "If your annotation has validated `True`, you can now assign these annotations to the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.annotate_images(images, annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 2 - Using the CNN to make predictions\n",
    "\n",
    "### Loading the pre-trained model\n",
    "\n",
    "In the following lines of code `helpers.load_CNN_model()` builds the CNN network, and sets the weights and biases using the pretrained values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = helpers.load_CNN_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='task_red'> <b>TASK:</b> Summarise the model and get the number of parameters. Answer the following questions:\n",
    "    <ul>\n",
    "        <li>How many convolutional layers are there? </li>\n",
    "        <li>How many kernels are used in each convolutional layer? </li>\n",
    "        <li>How many output classes are there? </li>\n",
    "        <li>What is the size of the input image, and after the convolutional layers?</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "**HINT**: You can use the command `model.summary()` to get the details of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise activations within the network\n",
    "\n",
    "When the network is given an example, we can visualize the activations within the networks from the sample. To visualize the activations within the network, you can use the `helpers.visualize_layers()` command.\n",
    "\n",
    "To do this, the function needs three (3) arguments:\n",
    "`helpers.visualize_layers(model, image, layer)`\n",
    "\n",
    "<br />\n",
    "\n",
    "<div class='task_red'><b>TASK:</b> visualize the activations within the network for the first and second convolutional layers (layer=0 or layer=1). What can you see? </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.visualize_layers(model, images[5], layer=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the predictions\n",
    "\n",
    "\n",
    "Now that we have loaded the pre-trained model. We can feed it the same images that you have labeled and generate predictions for the label. The predictions are returned as the probability of the label given the image data, $\\text{P}(\\text{label} | \\text{data})$. In fact, the model returns the probability for *all* labels given the data.\n",
    "\n",
    "<br />\n",
    "<div class=\"task_blue\"> <b>TASK:</b> Using the model, make predictions for the images that you have annotated.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_for_prediction = np.concatenate([im.as_tensor() for im in images], axis=0)\n",
    "predictions = model.predict(images_for_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the command `print()` to print the predictions to the screen.  Since `predictions` is a 2D array, it also has a shape. You can access the shape information using the `.shape` property.\n",
    "\n",
    "<br />\n",
    "\n",
    "<div class='task_red'><b>TASK:</b> Print the predictions to the screen. Why is the output this shape?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 3 - Compare the predictions with your annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the images and their predictions using one of the helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helpers.plot_predictions(images, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.print_predictions(images, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the confusion matrix\n",
    "\n",
    "By definition, a confusion matrix $\\mathbf{C}$ is such that $\\mathbf{C}_{i,j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 4 - Calculate the accuracy of the model using your ground truth data\n",
    "\n",
    "We need to determine the overall accuracy of the model. We will make several simple calculations:\n",
    "\n",
    "That is, precision is the fraction of events where we correctly declared i out of all instances where the algorithm declared i. Conversely, recall is the fraction of events where we correctly declared i out of all of the cases where the true of state of the world is i.\n",
    "\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "Accuracy is the proportion of true results among the total number of examples examined.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "Precision is \n",
    "\n",
    "#### Recall\n",
    "\n",
    "#### F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now write our own function to calculate the F1-score for each of the categories.\n",
    "\n",
    "A *function* is a block of code that takes some inputs (*arguments*) and performs a task, often returning a result. For example, a function that calculates the value of $y$ for a straight line $y=mx+c$ may look something like this:\n",
    "\n",
    "```python\n",
    "def straight_line(m, x, c):\n",
    "    y = m*x + c\n",
    "    return y\n",
    "```\n",
    "\n",
    "The `def` keyword means that we are defining a function. This is followed by the function name, which is `straight_line` in this case, with the arguments `(m, x, c)` in that order. The remainder is simply the calculation. The `return` keyword, returns the result `y` to the user.\n",
    "\n",
    "One can use the function as follows:\n",
    "```python\n",
    "y = straight_line(1, 10, 0)\n",
    "print(y)\n",
    "```\n",
    "\n",
    "which returns the result: `10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to create a function below, that calculates the $F_{1}$ score, according to the following equation:\n",
    "\n",
    "\\begin{equation}\n",
    "F_1 = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "\\end{equation}\n",
    "\n",
    "<br />\n",
    "\n",
    "<div class='task_red'><b>TASK:</b> Complete the function below to calculate the F1 score for each class </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(recall, precision):\n",
    "    \"\"\" Function to calculate the F1-score. You need to complete the function here. \"\"\"\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"task_red\"><b>TASK:</b> Please make sure you have completed the Google form and uploaded your results </div>\n",
    "\n",
    "# End of the practical\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
